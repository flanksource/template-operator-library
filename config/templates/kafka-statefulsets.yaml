apiVersion: templating.flanksource.com/v1
kind: Template
metadata:
  name: kafka
spec:
  source:
    apiVersion: db.flanksource.com/v1
    kind: KafkaCluster
  resources:
    - apiVersion: v1
      kind: Secret
      metadata:
        name: kafka-{{ .metadata.name }}-credentials
        namespace: '{{ .metadata.namespace }}'
      type: Opaque
      stringData:
        KAFKA_CLIENT_USER: kafka
        KAFKA_CLIENT_PASSWORD: '{{- kget (print "secret/" .metadata.namespace "/kafka-" .metadata.name "-credentials") "KAFKA_CLIENT_PASSWORD" | default (random.AlphaNum 16) -}}'
    - apiVersion: v1
      kind: ConfigMap
      metadata:
        name: '{{.metadata.name}}-kafka-scripts'
        namespace: '{{.metadata.namespace}}'
        labels:
          app.kubernetes.io/name: '{{.metadata.name}}-kafka'
      data:
        setup.sh: |-
          #!/bin/bash

          ID="${MY_POD_NAME#"{{.metadata.name}}-kafka-"}"
          if [[ -f "/bitnami/kafka/data/meta.properties" ]]; then
              export KAFKA_CFG_BROKER_ID="$(grep "broker.id" /bitnami/kafka/data/meta.properties | awk -F '=' '{print $2}')"
          else
              export KAFKA_CFG_BROKER_ID="$((ID + 0))"
          fi

          exec /entrypoint.sh /run.sh
    - apiVersion: v1
      kind: Service
      metadata:
        name: '{{.metadata.name}}-zookeeper-headless'
        namespace: '{{.metadata.namespace}}'
        labels:
          app.kubernetes.io/name: zookeeper
          app.kubernetes.io/component: zookeeper
      spec:
        type: ClusterIP
        clusterIP: None
        publishNotReadyAddresses: true
        ports:
          - name: tcp-client
            port: 2181
            targetPort: client
          - name: follower
            port: 2888
            targetPort: follower
          - name: tcp-election
            port: 3888
            targetPort: election
        selector:
          app.kubernetes.io/name: '{{.metadata.name}}-zookeeper'
          app.kubernetes.io/component: zookeeper
    - apiVersion: v1
      kind: Service
      metadata:
        name: '{{.metadata.name}}-zookeeper'
        namespace: '{{.metadata.namespace}}'
        labels:
          app.kubernetes.io/name: '{{.metadata.name}}-zookeeper'
          app.kubernetes.io/component: zookeeper
      spec:
        type: ClusterIP
        ports:
          - name: tcp-client
            port: 2181
            targetPort: client
          - name: follower
            port: 2888
            targetPort: follower
          - name: tcp-election
            port: 3888
            targetPort: election
        selector:
          app.kubernetes.io/name: '{{.metadata.name}}-zookeeper'
          app.kubernetes.io/component: zookeeper
    - apiVersion: v1
      kind: Service
      metadata:
        name: '{{.metadata.name}}-kafka-headless'
        namespace: '{{.metadata.namespace}}'
        labels:
          app.kubernetes.io/name: '{{.metadata.name}}-kafka'
          app.kubernetes.io/component: kafka
      spec:
        type: ClusterIP
        clusterIP: None
        ports:
          - name: tcp-client
            port: 9092
            protocol: TCP
            targetPort: kafka-client
          - name: tcp-internal
            port: 9093
            protocol: TCP
            targetPort: kafka-internal
        selector:
          app.kubernetes.io/name: '{{.metadata.name}}-kafka'
          app.kubernetes.io/component: kafka
    - apiVersion: v1
      kind: Service
      metadata:
        name: '{{.metadata.name}}-kafka'
        namespace: '{{.metadata.namespace}}'
        labels:
          app.kubernetes.io/name: '{{.metadata.name}}-kafka'
          app.kubernetes.io/component: kafka
      spec:
        type: ClusterIP
        ports:
          - name: tcp-client
            port: 9092
            protocol: TCP
            targetPort: kafka-client
            nodePort: null
        selector:
          app.kubernetes.io/name: '{{.metadata.name}}-kafka'
          app.kubernetes.io/component: kafka
    - apiVersion: v1
      kind: ServiceAccount
      metadata:
        name: '{{.metadata.name}}-kafka'
        namespace: '{{.metadata.namespace}}'
        labels:
          app.kubernetes.io/name: '{{.metadata.name}}-kafka'
          app.kubernetes.io/component: kafka
      automountServiceAccountToken: true
    - apiVersion: apps/v1
      kind: StatefulSet
      metadata:
        name: '{{.metadata.name}}-zookeeper'
        namespace: '{{.metadata.namespace}}'
        labels:
          app.kubernetes.io/name: '{{.metadata.name}}-zookeeper'
          app.kubernetes.io/component: zookeeper
          role: zookeeper
      spec:
        serviceName: '{{.metadata.name}}-zookeeper-headless'
        replicas: '{{.spec.zookeeper.replicas | default "3"}}'
        podManagementPolicy: Parallel
        updateStrategy:
          type: RollingUpdate
        selector:
          matchLabels:
            app.kubernetes.io/name: '{{.metadata.name}}-zookeeper'
            app.kubernetes.io/component: zookeeper
        template:
          metadata:
            name: '{{.metadata.name}}-zookeeper'
            labels:
              app.kubernetes.io/name: '{{.metadata.name}}-zookeeper'
              app.kubernetes.io/component: zookeeper
          spec:
            serviceAccountName: default
            securityContext:
              fsGroup: 1001
            containers:
              - name: zookeeper
                image: docker.io/bitnami/zookeeper:{{.spec.zookeeper.version | default "3.7.0-debian-10-r0" }}
                imagePullPolicy: IfNotPresent
                securityContext:
                  runAsUser: 1001
                command:
                  - bash
                  - -ec
                  - |
                    # Execute entrypoint as usual after obtaining ZOO_SERVER_ID
                    # check ZOO_SERVER_ID in persistent volume via myid
                    # if not present, set based on POD hostname
                    if [[ -f "/bitnami/zookeeper/data/myid" ]]; then
                      export ZOO_SERVER_ID="$(cat /bitnami/zookeeper/data/myid)"
                    else
                      HOSTNAME=`hostname -s`
                      if [[ $HOSTNAME =~ (.*)-([0-9]+)$ ]]; then
                        ORD=${BASH_REMATCH[2]}
                        export ZOO_SERVER_ID=$((ORD + 1 ))
                      else
                        echo "Failed to get index from hostname $HOST"
                        exit 1
                      fi
                    fi
                    exec /entrypoint.sh /run.sh
                resources:
                  requests:
                    cpu: '{{.spec.zookeeper.resources.requests.cpu | default "250m" }}'
                    memory: '{{.spec.zookeeper.resources.requests.memory | default "256Mi" }}'
                  limits:
                    cpu: '{{.spec.zookeeper.resources.limits.cpu | default "500m" }}'
                    memory: '{{.spec.zookeeper.resources.limits.memory | default "512Mi" }}'
                env:
                  - name: ZOO_DATA_LOG_DIR
                    value: ""
                  - name: ZOO_PORT_NUMBER
                    value: "2181"
                  - name: ZOO_TICK_TIME
                    value: "2000"
                  - name: ZOO_INIT_LIMIT
                    value: "10"
                  - name: ZOO_SYNC_LIMIT
                    value: "5"
                  - name: ZOO_MAX_CLIENT_CNXNS
                    value: "60"
                  - name: ZOO_4LW_COMMANDS_WHITELIST
                    value: srvr, mntr, ruok
                  - name: ZOO_LISTEN_ALLIPS_ENABLED
                    value: yes
                  - name: ZOO_AUTOPURGE_INTERVAL
                    value: "0"
                  - name: ZOO_AUTOPURGE_RETAIN_COUNT
                    value: "3"
                  - name: ZOO_MAX_SESSION_TIMEOUT
                    value: "40000"
                  - name: ZOO_SERVERS
                    value: '{{.metadata.name}}-zookeeper-0.{{.metadata.name}}-zookeeper-headless.{{.metadata.namespace}}.svc.cluster.local:2888:3888;{{.metadata.name}}-zookeeper-1.{{.metadata.name}}-zookeeper-headless.{{.metadata.namespace}}.svc.cluster.local:2888:3888;{{.metadata.name}}-zookeeper-2.{{.metadata.name}}-zookeeper-headless.{{.metadata.namespace}}.svc.cluster.local:2888:3888'
                  - name: ZOO_ENABLE_AUTH
                    value: no
                  - name: ZOO_HEAP_SIZE
                    value: "1024"
                  - name: ZOO_LOG_LEVEL
                    value: ALL
                  - name: ALLOW_ANONYMOUS_LOGIN
                    value: yes
                  - name: POD_NAME
                    valueFrom:
                      fieldRef:
                        apiVersion: v1
                        fieldPath: metadata.name
                ports:
                  - name: client
                    containerPort: 2181
                  - name: follower
                    containerPort: 2888
                  - name: election
                    containerPort: 3888
                livenessProbe:
                  exec:
                    command:
                      - /bin/bash
                      - -c
                      - echo "ruok" | timeout 2 nc -w 2 localhost 2181 | grep imok
                  initialDelaySeconds: 30
                  periodSeconds: 10
                  timeoutSeconds: 5
                  successThreshold: 1
                  failureThreshold: 6
                readinessProbe:
                  exec:
                    command:
                      - /bin/bash
                      - -c
                      - echo "ruok" | timeout 2 nc -w 2 localhost 2181 | grep imok
                  initialDelaySeconds: 5
                  periodSeconds: 10
                  timeoutSeconds: 5
                  successThreshold: 1
                  failureThreshold: 6
                volumeMounts:
                  - name: data
                    mountPath: /bitnami/zookeeper
            volumes:
        volumeClaimTemplates:
          - metadata:
              name: data
              annotations:
            spec:
              accessModes:
                - ReadWriteOnce
              resources:
                requests:
                  storage: '{{.spec.zookeeper.storage.size | default "8Gi" }}'
                storageClass: '{{.spec.zookeeper.storage.storageClass}}'
    - apiVersion: apps/v1
      kind: StatefulSet
      metadata:
        name: '{{.metadata.name}}-kafka'
        namespace: '{{.metadata.namespace}}'
        labels:
          app.kubernetes.io/name: '{{.metadata.name}}-kafka'
          app.kubernetes.io/component: kafka
      spec:
        podManagementPolicy: Parallel
        replicas: '{{.spec.kafka.replicas | default "3" }}'
        selector:
          matchLabels:
            app.kubernetes.io/name: '{{.metadata.name}}-kafka'
            app.kubernetes.io/component: kafka
        serviceName: '{{.metadata.name}}-kafka-headless'
        updateStrategy:
          type: RollingUpdate
        template:
          metadata:
            labels:
              app.kubernetes.io/name: '{{.metadata.name}}-kafka'
              app.kubernetes.io/component: kafka
          spec:
            securityContext:
              fsGroup: 1001
              runAsUser: 1001
            serviceAccountName: '{{.metadata.name}}-kafka'
            containers:
              - name: kafka
                image: docker.io/bitnami/kafka:{{.spec.kafka.version | default "2.8.0-debian-10-r0" }}
                imagePullPolicy: IfNotPresent
                command:
                  - /scripts/setup.sh
                envFrom:
                  - secretRef:
                      name: kafka-{{ .metadata.name }}-credentials
                env:
                  - name: BITNAMI_DEBUG
                    value: "false"
                  - name: MY_POD_IP
                    valueFrom:
                      fieldRef:
                        fieldPath: status.podIP
                  - name: MY_POD_NAME
                    valueFrom:
                      fieldRef:
                        fieldPath: metadata.name
                  - name: KAFKA_CFG_ZOOKEEPER_CONNECT
                    value: '{{.metadata.name}}-zookeeper-headless'
                  - name: KAFKA_INTER_BROKER_LISTENER_NAME
                    value: INTERNAL
                  - name: KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP
                    value: INTERNAL:PLAINTEXT,CLIENT:PLAINTEXT
                  - name: KAFKA_CFG_LISTENERS
                    value: INTERNAL://:9093,CLIENT://:9092
                  - name: KAFKA_CFG_ADVERTISED_LISTENERS
                    value: INTERNAL://$(MY_POD_NAME).{{.metadata.name}}-kafka-headless.{{.metadata.namespace}}.svc.cluster.local:9093,CLIENT://$(MY_POD_IP):9092
                  - name: ALLOW_PLAINTEXT_LISTENER
                    value: yes
                  - name: KAFKA_VOLUME_DIR
                    value: /bitnami/kafka
                  - name: KAFKA_LOG_DIR
                    value: /opt/bitnami/kafka/logs
                  - name: KAFKA_CFG_DELETE_TOPIC_ENABLE
                    value: "false"
                  - name: KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE
                    value: "true"
                  - name: KAFKA_HEAP_OPTS
                    value: -Xmx1024m -Xms1024m
                  - name: KAFKA_CFG_LOG_FLUSH_INTERVAL_MESSAGES
                    value: "10000"
                  - name: KAFKA_CFG_LOG_FLUSH_INTERVAL_MS
                    value: "1000"
                  - name: KAFKA_CFG_LOG_RETENTION_BYTES
                    value: "1073741824"
                  - name: KAFKA_CFG_LOG_RETENTION_CHECK_INTERVALS_MS
                    value: "300000"
                  - name: KAFKA_CFG_LOG_RETENTION_HOURS
                    value: "168"
                  - name: KAFKA_CFG_MESSAGE_MAX_BYTES
                    value: "1000012"
                  - name: KAFKA_CFG_LOG_SEGMENT_BYTES
                    value: "1073741824"
                  - name: KAFKA_CFG_LOG_DIRS
                    value: /bitnami/kafka/data
                  - name: KAFKA_CFG_DEFAULT_REPLICATION_FACTOR
                    value: "1"
                  - name: KAFKA_CFG_OFFSETS_TOPIC_REPLICATION_FACTOR
                    value: "1"
                  - name: KAFKA_CFG_TRANSACTION_STATE_LOG_REPLICATION_FACTOR
                    value: "1"
                  - name: KAFKA_CFG_TRANSACTION_STATE_LOG_MIN_ISR
                    value: "1"
                  - name: KAFKA_CFG_NUM_IO_THREADS
                    value: "8"
                  - name: KAFKA_CFG_NUM_NETWORK_THREADS
                    value: "3"
                  - name: KAFKA_CFG_NUM_PARTITIONS
                    value: "1"
                  - name: KAFKA_CFG_NUM_RECOVERY_THREADS_PER_DATA_DIR
                    value: "1"
                  - name: KAFKA_CFG_SOCKET_RECEIVE_BUFFER_BYTES
                    value: "102400"
                  - name: KAFKA_CFG_SOCKET_REQUEST_MAX_BYTES
                    value: "104857600"
                  - name: KAFKA_CFG_SOCKET_SEND_BUFFER_BYTES
                    value: "102400"
                  - name: KAFKA_CFG_ZOOKEEPER_CONNECTION_TIMEOUT_MS
                    value: "6000"
                ports:
                  - name: kafka-client
                    containerPort: 9092
                  - name: kafka-internal
                    containerPort: 9093
                livenessProbe:
                  tcpSocket:
                    port: kafka-client
                  initialDelaySeconds: 10
                  timeoutSeconds: 5
                  failureThreshold:
                  periodSeconds:
                  successThreshold:
                readinessProbe:
                  tcpSocket:
                    port: kafka-client
                  initialDelaySeconds: 5
                  timeoutSeconds: 5
                  failureThreshold: 6
                  periodSeconds:
                  successThreshold:
                resources:
                  requests:
                    cpu: '{{.spec.kafka.resources.requests.cpu | default "500m" }}'
                    memory: '{{.spec.kafka.resources.requests.memory | default "4Gi" }}'
                  limits:
                    cpu: '{{.spec.kafka.resources.limits.cpu | default "1000m" }}'
                    memory: '{{.spec.kafka.resources.limits.memory | default "8Gi" }}'
                volumeMounts:
                  - name: data
                    mountPath: /bitnami/kafka
                  - name: logs
                    mountPath: /opt/bitnami/kafka/logs
                  - name: scripts
                    mountPath: /scripts/setup.sh
                    subPath: setup.sh
            volumes:
              - name: scripts
                configMap:
                  name: '{{.metadata.name}}-kafka-scripts'
                  defaultMode: 0755
              - name: logs
                emptyDir: {}
        volumeClaimTemplates:
          - metadata:
              name: data
            spec:
              accessModes:
                - ReadWriteOnce
              resources:
                requests:
                  storage: '{{.spec.kafka.storage.size | default "20Gi" }}'
                storageClass: '{{.spec.kafka.storage.storageClass}}'
    - apiVersion: v1
      kind: Secret
      metadata:
        name: '{{.metadata.name}}-hq-secrets'
        namespace: '{{.metadata.namespace}}'
        labels:
          app.kubernetes.io/name: '{{.metadata.name}}-hq'
      type: Opaque
      data:
        application-secrets.yml: ""
    - apiVersion: v1
      kind: ConfigMap
      metadata:
        name: '{{.metadata.name}}-hq'
        namespace: '{{.metadata.namespace}}'
        labels:
          app.kubernetes.io/name: '{{.metadata.name}}-hq'
      data:
        application.yml: |
          akhq:
            connections:
              {{.metadata.name}}:
                properties:
                  bootstrap.servers: "{{.metadata.name}}-kafka:9092"
            server:
              access-log:
                enabled: false
                name: org.akhq.log.access
    - apiVersion: v1
      kind: Service
      metadata:
        name: '{{.metadata.name}}-hq'
        namespace: '{{.metadata.namespace}}'
        labels:
          app.kubernetes.io/name: '{{.metadata.name}}-hq'
      spec:
        type: ClusterIP
        ports:
          - port: 80
            targetPort: http
            protocol: TCP
            name: http
        selector:
          app.kubernetes.io/name: '{{.metadata.name}}-hq'
    - apiVersion: extensions/v1beta1
      kind: Ingress
      metadata:
        name: '{{ .metadata.name }}-hq-ingress'
        namespace: '{{ .metadata.namespace }}'
        annotations:
          kubernetes.io/tls-acme: true
      spec:
        tls:
          - secretName: '{{ .metadata.name }}-hq-tls'
            hosts:
              - '{{ .metadata.name }}-hq.{{.metadata.namespace}}.{{kget "cm/quack/quack-config" "data.domain"}}'
        rules:
          - host: '{{ .metadata.name }}-hq.{{.metadata.namespace}}.{{kget "cm/quack/quack-config" "data.domain"}}'
            http:
              paths:
                - backend:
                    serviceName: '{{.metadata.name}}-hq'
                    servicePort: 80
    - apiVersion: apps/v1
      kind: Deployment
      metadata:
        name: '{{.metadata.name}}-hq'
        namespace: '{{.metadata.namespace}}'
        labels:
          app.kubernetes.io/name: '{{.metadata.name}}-hq'
      spec:
        replicas: 1
        selector:
          matchLabels:
            app.kubernetes.io/name: '{{.metadata.name}}-hq'
        template:
          metadata:
            labels:
              app.kubernetes.io/name: '{{.metadata.name}}-hq'
          spec:
            containers:
              - name: akhq
                image: docker.io/tchiotludo/akhq:0.17.0
                imagePullPolicy: Always
                env:
                  - name: MICRONAUT_ENVIRONMENTS
                    value: secrets
                  - name: MICRONAUT_CONFIG_FILES
                    value: /app/application.yml,/app/application-secrets.yml
                volumeMounts:
                  - name: config
                    mountPath: /app/application.yml
                    subPath: application.yml
                  - name: secrets
                    mountPath: /app/application-secrets.yml
                    subPath: application-secrets.yml
                ports:
                  - name: http
                    containerPort: 8080
                    protocol: TCP
                  - name: management
                    containerPort: 8081
                    protocol: TCP
                livenessProbe:
                  tcpSocket:
                    port: management
                readinessProbe:
                  httpGet:
                    path: /health
                    port: management
                resources: {}
            volumes:
              - name: config
                configMap:
                  name: '{{.metadata.name}}-hq'
              - name: secrets
                secret:
                  secretName: '{{.metadata.name}}-hq-secrets'
